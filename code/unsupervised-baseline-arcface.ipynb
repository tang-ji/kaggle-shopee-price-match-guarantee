{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006222,
     "end_time": "2021-03-18T18:45:27.158483",
     "exception": false,
     "start_time": "2021-03-18T18:45:27.152261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Comments\n",
    "\n",
    "Thanks to Chris for this great notebook https://www.kaggle.com/cdeotte/part-2-rapids-tfidfvectorizer-cv-0-700. \n",
    "\n",
    "Here is the script for the EfficientNetb3 ArcFace Model https://www.kaggle.com/ragnar123/shopee-efficientnetb3-arcmarginproduct\n",
    "\n",
    "Here is the script for the Bert Model https://www.kaggle.com/ragnar123/bert-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-18T18:45:27.180604Z",
     "iopub.status.busy": "2021-03-18T18:45:27.180059Z",
     "iopub.status.idle": "2021-03-18T18:46:30.130439Z",
     "shell.execute_reply": "2021-03-18T18:46:30.129246Z"
    },
    "papermill": {
     "duration": 62.966824,
     "end_time": "2021-03-18T18:46:30.130652",
     "exception": false,
     "start_time": "2021-03-18T18:45:27.163828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.15.0)\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Processing /kaggle/input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.18.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.4)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2021.2.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.3.3)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.9.0)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.5)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl\n",
    "!pip install ../input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from shutil import copyfile\n",
    "copyfile(src = \"../input/shopee-external-models/tokenization.py\", dst = \"../working/tokenization.py\")\n",
    "import tokenization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T18:46:30.156538Z",
     "iopub.status.busy": "2021-03-18T18:46:30.154759Z",
     "iopub.status.idle": "2021-03-18T18:46:30.157174Z",
     "shell.execute_reply": "2021-03-18T18:46:30.157560Z"
    },
    "papermill": {
     "duration": 0.018868,
     "end_time": "2021-03-18T18:46:30.157683",
     "exception": false,
     "start_time": "2021-03-18T18:46:30.138815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = [512, 512]\n",
    "# Seed\n",
    "SEED = 42\n",
    "# Verbosity\n",
    "VERBOSE = 1\n",
    "# Number of classes\n",
    "N_CLASSES = 11011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T18:46:30.335166Z",
     "iopub.status.busy": "2021-03-18T18:46:30.334507Z",
     "iopub.status.idle": "2021-03-18T18:46:34.978197Z",
     "shell.execute_reply": "2021-03-18T18:46:34.977340Z"
    },
    "papermill": {
     "duration": 4.813077,
     "end_time": "2021-03-18T18:46:34.978346",
     "exception": false,
     "start_time": "2021-03-18T18:46:30.165269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will restrict TensorFlow to max 2GB GPU RAM\n",
      "then RAPIDS can use 14GB GPU RAM\n"
     ]
    }
   ],
   "source": [
    "# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n",
    "# SO THAT WE HAVE 14GB RAM FOR RAPIDS\n",
    "LIMIT = 2.0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
    "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T18:46:35.043699Z",
     "iopub.status.busy": "2021-03-18T18:46:35.021662Z",
     "iopub.status.idle": "2021-03-18T18:58:40.378275Z",
     "shell.execute_reply": "2021-03-18T18:58:40.378680Z"
    },
    "papermill": {
     "duration": 725.391989,
     "end_time": "2021-03-18T18:58:40.378850",
     "exception": false,
     "start_time": "2021-03-18T18:46:34.986861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (34250, 1536)\n",
      "Our text embeddings shape is (34250, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "370597"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flag to get cv score\n",
    "GET_CV = True\n",
    "# Flag to check ram allocations (debug)\n",
    "CHECK_SUB = False\n",
    "\n",
    "df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "# If we are comitting, replace train set for test set and dont get cv\n",
    "if len(df) > 3:\n",
    "    GET_CV = False\n",
    "del df\n",
    "\n",
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "# Function to combine predictions\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
    "    return ' '.join( np.unique(x) )\n",
    "\n",
    "# Function to read out dataset\n",
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "        \n",
    "    return df, df_cu, image_paths\n",
    "\n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "# Arcmarginproduct class keras layer\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Function to get the embeddings of our images with the fine-tuned model\n",
    "def get_image_embeddings(image_paths):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.7, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB3(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights('../input/shopee-external-models/EfficientNetB3_M0.7_512_42.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "# Return tokens, masks and segments from a text array or series\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "# Function to get our text title embeddings using a pre-trained bert model\n",
    "def get_text_embeddings(df, max_len = 70):\n",
    "    embeds = []\n",
    "    module_url = \"../input/shopee-external-models/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = 11014, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'label')\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    x = margin([clf_output, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n",
    "    \n",
    "    model.load_weights('../input/shopee-bert-baseline/Bert_123.h5')\n",
    "    model = tf.keras.models.Model(inputs = model.input[0:3], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        text_chunk = ((text[0][a:b], text[1][a:b], text[2][a:b]))\n",
    "        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n",
    "        embeds.append(text_embeddings)\n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings\n",
    "    \n",
    "# Function to get 50 nearest neighbors of each image and apply a distance threshold to maximize cv\n",
    "def get_neighbors(df, embeddings, KNN = 50, image = True):\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if GET_CV:\n",
    "        if image:\n",
    "            thresholds = list(np.arange(3.0, 5.0, 0.1))\n",
    "        else:\n",
    "            thresholds = list(np.arange(15, 35, 1))\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 3.3)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 18.0)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "    \n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < 3.3)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 18.0)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions\n",
    "    \n",
    "\n",
    "df, df_cu, image_paths = read_dataset()\n",
    "image_embeddings = get_image_embeddings(image_paths)\n",
    "text_embeddings = get_text_embeddings(df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T18:58:40.401866Z",
     "iopub.status.busy": "2021-03-18T18:58:40.401051Z",
     "iopub.status.idle": "2021-03-18T18:59:40.371946Z",
     "shell.execute_reply": "2021-03-18T18:59:40.370922Z"
    },
    "papermill": {
     "duration": 59.984031,
     "end_time": "2021-03-18T18:59:40.372096",
     "exception": false,
     "start_time": "2021-03-18T18:58:40.388065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1 score for threshold 3.0 is 0.7712513459265644\n",
      "Our f1 score for threshold 3.1 is 0.7844542782549174\n",
      "Our f1 score for threshold 3.2 is 0.7967592602060737\n",
      "Our f1 score for threshold 3.3000000000000003 is 0.8091234701540835\n",
      "Our f1 score for threshold 3.4000000000000004 is 0.820439264997903\n",
      "Our f1 score for threshold 3.5000000000000004 is 0.8308724892933443\n",
      "Our f1 score for threshold 3.6000000000000005 is 0.8390411731647424\n",
      "Our f1 score for threshold 3.7000000000000006 is 0.8464272146335603\n",
      "Our f1 score for threshold 3.8000000000000007 is 0.851885640004961\n",
      "Our f1 score for threshold 3.900000000000001 is 0.8538250287562849\n",
      "Our f1 score for threshold 4.000000000000001 is 0.850299268986875\n",
      "Our f1 score for threshold 4.100000000000001 is 0.8370624753262246\n",
      "Our f1 score for threshold 4.200000000000001 is 0.8129799844201347\n",
      "Our f1 score for threshold 4.300000000000001 is 0.7732162140331378\n",
      "Our f1 score for threshold 4.400000000000001 is 0.7216339958937074\n",
      "Our f1 score for threshold 4.500000000000002 is 0.6593320279819707\n",
      "Our f1 score for threshold 4.600000000000001 is 0.5936933712075643\n",
      "Our f1 score for threshold 4.700000000000001 is 0.5308589580622944\n",
      "Our f1 score for threshold 4.800000000000002 is 0.47411749535996195\n",
      "Our f1 score for threshold 4.900000000000002 is 0.4257481423454245\n",
      "Our best score is 0.8538250287562849 and has a threshold 3.900000000000001\n"
     ]
    }
   ],
   "source": [
    "# Get neighbors for image_embeddings\n",
    "df, image_predictions = get_neighbors(df, image_embeddings, KNN = 50, image = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T18:59:40.405317Z",
     "iopub.status.busy": "2021-03-18T18:59:40.404082Z",
     "iopub.status.idle": "2021-03-18T19:00:41.172997Z",
     "shell.execute_reply": "2021-03-18T19:00:41.172452Z"
    },
    "papermill": {
     "duration": 60.786839,
     "end_time": "2021-03-18T19:00:41.173144",
     "exception": false,
     "start_time": "2021-03-18T18:59:40.386305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1 score for threshold 15 is 0.7238552100161499\n",
      "Our f1 score for threshold 16 is 0.7521345543048372\n",
      "Our f1 score for threshold 17 is 0.7734936534171709\n",
      "Our f1 score for threshold 18 is 0.7888265737308165\n",
      "Our f1 score for threshold 19 is 0.8004339589741449\n",
      "Our f1 score for threshold 20 is 0.809999894130618\n",
      "Our f1 score for threshold 21 is 0.818520857776994\n",
      "Our f1 score for threshold 22 is 0.8256861424748175\n",
      "Our f1 score for threshold 23 is 0.8321857561917364\n",
      "Our f1 score for threshold 24 is 0.8357137744113223\n",
      "Our f1 score for threshold 25 is 0.8349425196390452\n",
      "Our f1 score for threshold 26 is 0.8210367434247451\n",
      "Our f1 score for threshold 27 is 0.7755642352158231\n",
      "Our f1 score for threshold 28 is 0.6776454360852282\n",
      "Our f1 score for threshold 29 is 0.465920281858341\n",
      "Our f1 score for threshold 30 is 0.18050521981438802\n",
      "Our f1 score for threshold 31 is 0.17850330775052395\n",
      "Our f1 score for threshold 32 is 0.17850330775052395\n",
      "Our f1 score for threshold 33 is 0.17850330775052395\n",
      "Our f1 score for threshold 34 is 0.17850330775052395\n",
      "Our best score is 0.8357137744113223 and has a threshold 24\n"
     ]
    }
   ],
   "source": [
    "# Get neighbors for text_embeddings\n",
    "df, text_predictions = get_neighbors(df, text_embeddings, KNN = 50, image = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T19:00:41.224191Z",
     "iopub.status.busy": "2021-03-18T19:00:41.223612Z",
     "iopub.status.idle": "2021-03-18T19:00:42.871415Z",
     "shell.execute_reply": "2021-03-18T19:00:42.870447Z"
    },
    "papermill": {
     "duration": 1.678832,
     "end_time": "2021-03-18T19:00:42.871574",
     "exception": false,
     "start_time": "2021-03-18T19:00:41.192742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final f1 cv score is 0.9009886685266703\n"
     ]
    }
   ],
   "source": [
    "# Concatenate image predctions with text predictions\n",
    "if GET_CV:\n",
    "    df['image_predictions'] = image_predictions\n",
    "    df['text_predictions'] = text_predictions\n",
    "    df['pred_matches'] = df.apply(combine_predictions, axis = 1)\n",
    "    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "    score = df['f1'].mean()\n",
    "    print(f'Our final f1 cv score is {score}')\n",
    "    df['matches'] = df['pred_matches']\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "else:\n",
    "    df['image_predictions'] = image_predictions\n",
    "    df['text_predictions'] = text_predictions\n",
    "    df['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 922.878882,
   "end_time": "2021-03-18T19:00:45.428721",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-18T18:45:22.549839",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
